# 2026-02-14 15:24:13 CI侧车镜像改为官方转推并拆分独立Job

## 背景

GitHub Actions 在构建 `sidecar/llamacpp-glm5/Dockerfile` 时失败，报错为链接阶段找不到 `libcuda.so.1`，并出现 `cuMemCreate/cuMemMap` 等符号未解析。

这类错误发生在 CI 构建容器内较常见，属于 CUDA driver 动态库链接问题，不影响线上运行时（宿主机注入驱动）本身，但会阻塞镜像发布流程。

## 本次调整

1. 更新 `.github/workflows/docker-acr.yml`：
- 将流水线拆成两个独立 job：
  - `docker-main`：继续构建并推送主镜像。
  - `docker-sidecar-mirror`：不再源码编译 sidecar，改为将官方镜像转推到 ACR。
- `workflow_dispatch` 输入由 `llamacpp_ref` 改为 `sidecar_source_image`。
- sidecar 默认来源：`ghcr.io/ggml-org/llama.cpp:server-cuda`。
- sidecar 标签规范改为：`<image_version>-llamacpp-official`。

2. 更新 `README.md`：
- 同步新的 action 输入参数与标签规范。
- 明确说明 sidecar 在 CI 中使用“官方镜像转推”，不做源码编译。
- 保留本地源码构建兜底方案（`glm5-sidecar-localbuild`）。

## 效果

- 避开 CI 里 llama.cpp CUDA 链接失败导致的整条流水线中断。
- 主镜像和 sidecar 发布路径解耦，便于独立排障。
- 线上默认优先使用官方最新 sidecar，实现更稳定的发布。

## 使用提示

手动触发 workflow 时，如需指定 sidecar 来源镜像，可设置：

```bash
sidecar_source_image=ghcr.io/ggml-org/llama.cpp:server-cuda
```

如果官方镜像后续不满足需求，再使用本地 compose 的 `glm5-sidecar-localbuild` 进行源码构建兜底。
