# Dockerfile æ›´æ–°ï¼švLLM å‡çº§ã€SGLang æœ€æ–°ç‰ˆã€code-server é›†æˆ

## æ—¥æœŸ
2026-03-01

## å˜æ›´å†…å®¹

### 1. vLLM å‡çº§åˆ° nightly (0.16.1.dev)
- **åŸå› **: åŸ vLLM 0.8.3 ä¸æ”¯æŒ Step3p5ForCausalLM æ¶æ„
- **æ–°ç‰ˆæœ¬**: 0.16.1.dev (nightly build)
- **å®‰è£…æ–¹å¼**:
  ```dockerfile
  ARG VLLM_VERSION=0.16.1.dev
  pip3 install vllm==${VLLM_VERSION} \
    --extra-index-url https://wheels.vllm.ai/nightly \
    --extra-index-url https://download.pytorch.org/whl/cu129
  ```

### 2. SGLang å®‰è£…æœ€æ–°ç‰ˆæœ¬
- **å®˜æ–¹æ¨èå®‰è£…æ–¹å¼**: ä½¿ç”¨ uv ä» git å®‰è£…
- **å®‰è£…å‘½ä»¤**:
  ```dockerfile
  uv pip install --system 'git+https://github.com/sgl-project/sglang.git#subdirectory=python&egg=sglang[all]'
  ```

### 3. code-server é›†æˆ
- **å®‰è£…ä½ç½®**: ä¸ OpenCode ç›¸åŒçš„æ—©æœŸ Dockerfile å±‚ï¼ˆä¸å¸¸å˜æ›´ï¼ŒåŠ é€Ÿæ„å»ºï¼‰
- **å®‰è£…å‘½ä»¤**:
  ```dockerfile
  # Install code-server
  curl -fsSL https://code-server.dev/install.sh | sh
  # Install opencode plugin for code-server via VSCode Marketplace
  code-server --install-extension sst-dev.opencode --force
  ```
- **é»˜è®¤ç«¯å£**: 9000
- **ç¯å¢ƒå˜é‡**:
  - `CODE_SERVER_HOST`: é»˜è®¤ "0.0.0.0"
  - `CODE_SERVER_PORT`: é»˜è®¤ "9000"
  - `CODE_SERVER_PASSWORD`: å¯é€‰ï¼Œç”¨äºè®¤è¯
  - `CODE_SERVER_WORKSPACE`: é»˜è®¤ "/workspace"

### 4. start.sh æ›´æ–°
- æ–°å¢ code-server å¯åŠ¨é€»è¾‘
- æ–°å¢ PID_CODE_SERVER è¿›ç¨‹ç«¯å£ç®¡ç†
- æ·»åŠ  9000 åˆ° EXPOSE
- æ–°å¢å¯åŠ¨è¯Šæ–­ä¿¡æ¯è¾“å‡º

### 5. å¯åŠ¨è¯Šæ–­ä¿¡æ¯ (start.sh)
å¯åŠ¨æ—¶è¾“å‡ºä»¥ä¸‹ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œç¡®è®¤æ„å»ºç‰ˆæœ¬ï¼š

```bash
# æ„å»ºç‰ˆæœ¬
ğŸ“¦ Git Commit: abc12345

# ç³»ç»Ÿä¿¡æ¯
ğŸ–¥ï¸  OS: Ubuntu 22.04.3 LTS
ğŸ³ Container ID: abc123def456

# GPU ä¿¡æ¯
ğŸ® GPU Count: 1
ğŸ®    GPU: NVIDIA H200 SXM2-141GB, 141GB, 535.154.03, 12.2

# AI ç»„ä»¶
ğŸ Python: 3.11.x
ğŸ”¥ vLLM: 0.16.1.dev
ğŸŒ SGLang: 0.x.x
ğŸ¦™ llama.cpp: 1.x

# å·¥å…·é“¾
ğŸ¤– OpenCode: 1.2.15
ğŸ“ code-server: 4.x.x
ğŸ“¦ Node.js: 22.14.0
ğŸ§Š Bun: 1.x.x
ğŸ“ pnpm: 10.28.1
```

### 6. Dockerfile Git Commit è®°å½•
åœ¨ Dockerfile ä¸­æ·»åŠ  .git_commit æ–‡ä»¶ç”Ÿæˆï¼Œç¡®ä¿è¿è¡Œæ—¶å¯è·å–æ„å»ºç‰ˆæœ¬ï¼š

```dockerfile
RUN if command -v git >/dev/null 2>&1 && [[ -d /workspace/.git ]]; then \
      git -C /workspace rev-parse HEAD > /workspace/.git_commit; \
    else \
      echo "unknown" > /workspace/.git_commit; \
    fi
```

## éªŒè¯ç»“æœ

å½“å‰å®¹å™¨è¯Šæ–­è¾“å‡ºç¤ºä¾‹ï¼ˆé‡å»ºåå°†æ˜¾ç¤ºå®Œæ•´ä¿¡æ¯ï¼‰ï¼š

```
[INFO] ==========================================
[INFO] ğŸš€ Container Startup Diagnostics
[INFO] ==========================================
[INFO] --- Build Info ---
[INFO] ğŸ“¦ Git Commit: abc12345          # é‡å»ºåæ˜¾ç¤º
[INFO] --- System Info ---
[INFO] ğŸ–¥ï¸  OS: Ubuntu 22.04.4 LTS
[INFO] ğŸ• Start Time: 2026-03-01 14:40:56 UTC
[INFO] ğŸ³ Container ID: nn-h200-136-141g-1-xxx
[INFO] --- GPU Info ---
[INFO] ğŸ® GPU Count: 2
[INFO]    GPU: NVIDIA H200, 141GB, 575.57.08
[INFO]    CUDA: 12.9
[INFO] --- AI Components ---
[INFO] ğŸ Python: Python 3.10.12
[INFO] ğŸ”¥ vLLM: 0.16.1.dev              # é‡å»ºåæ˜¾ç¤º
[INFO] ğŸŒ SGLang: 0.6.0+                # é‡å»ºåæ˜¾ç¤º
[INFO] --- Inference Engine ---
[INFO] ğŸ¦™ llama.cpp: v8182 (05728db18)
[INFO] --- Additional Tools ---
[INFO] ğŸ¤– OpenCode: 1.2.15
[INFO] ğŸ“ code-server: 4.97.2            # é‡å»ºåæ˜¾ç¤º
[INFO] ğŸ“¦ Node.js: v22.14.0
[INFO] ğŸ§Š Bun: 1.3.10
[INFO] ğŸ“ pnpm: 10.28.1
[INFO] ==========================================
[INFO] âœ… Diagnostics Complete
[INFO] ==========================================
```

## å·²çŸ¥é—®é¢˜

### Step-3.5-Flash-FP8 GPU éœ€æ±‚
- å®˜æ–¹æ–‡æ¡£è¦æ±‚ **4xH200 GPUs** æ‰èƒ½è¿è¡Œ
- å½“å‰ç¡¬ä»¶: å•ä¸ª H200 MIG 7g.141gb (~141GB)
- **ç»“è®º**: ç¡¬ä»¶ä¸è¶³ï¼Œæ— æ³•è¿è¡Œ Step-3.5-Flash-FP8

### æ›¿ä»£æ–¹æ¡ˆ
- å°è¯• Qwen3.5-27B-FP8 (éœ€è¦ tensor parallel size 2)

## ç›¸å…³æ–‡ä»¶
- `/workspace/repos/Run-ComfyUI-Ollama/Dockerfile`
- `/workspace/repos/Run-ComfyUI-Ollama/start.sh`
