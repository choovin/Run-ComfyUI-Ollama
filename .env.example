# Docker image tag
IMAGE_TAG=latest

# Host port mapping
LLAMACPP_PORT=8080
OPENCODE_MANAGER_PORT=5003

# llama.cpp runtime (GLM-4.7-Flash quantized GGUF)
LLAMACPP_HOST=0.0.0.0
LLAMACPP_MODEL_PATH=/models/glm-4.7-flash-q4_k_m.gguf
LLAMACPP_ALIAS=glm47flash
LLAMACPP_CTX_SIZE=8192
LLAMACPP_N_GPU_LAYERS=999
LLAMACPP_THREADS=16
LLAMACPP_PARALLEL=1
# Optional extra args passed directly to llama-server
LLAMACPP_EXTRA_ARGS=

# OpenCode Manager runtime
OPENCODE_MANAGER_HOST=0.0.0.0
NODE_ENV=production
WORKSPACE_PATH=/workspace
DATABASE_PATH=/workspace/opencode-manager/data/opencode.db
# Leave empty to auto-generate at runtime (recommended to set fixed value in production)
AUTH_SECRET=
AUTH_TRUSTED_ORIGINS=http://127.0.0.1:5003,http://localhost:5003
AUTH_SECURE_COOKIES=false
